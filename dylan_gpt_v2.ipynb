{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "collapsed_sections": [
        "B3y7lfaPKTsr",
        "cllahlv10aq4",
        "UesWYZfDb7rK"
      ],
      "authorship_tag": "ABX9TyMNLRUiG1g++uHJcm89D+xJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafasacaan/dylan-gpt/blob/main/dylan_gpt_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks7tiVrUbt6m",
        "outputId": "1c468eb0-ee66-4de7-b16e-aff393153d81"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "Z3SqoupBncZm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIaRgReAPFPr",
        "outputId": "6c7f34fd-7b29-4d48-a65d-3019e7e54a78"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"{device=}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcKDH3B5PB3W",
        "outputId": "e7f0527b-3a80-47f7-a584-11ecd367f309"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device=device(type='cuda')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed\n",
        "torch.manual_seed(1337)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8Fi2H4eOF8I",
        "outputId": "8d1fc223-a603-4f6f-8c4a-e4021e9711e8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c1d1584f3f0>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Names data"
      ],
      "metadata": {
        "id": "oXXdyMtpOXRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data found in kaggle [here](https://www.kaggle.com/datasets/cloudy17/bob-dylan-songs)"
      ],
      "metadata": {
        "id": "Ry8ha8_kO28m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "id": "KgNVgaTyQeGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c39f078-d777-4716-91b4-aa1889fd62c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-09 14:20:59--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.1’\n",
            "\n",
            "input.txt.1         100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-08-09 14:20:59 (57.6 MB/s) - ‘input.txt.1’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# Here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "l4pYlm7aQkN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1GBdSamQpyy",
        "outputId": "748cc028-d8bf-4547-d70c-216c781fe917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z48ZlWZaQmtH",
        "outputId": "7317ddc3-3e76-4f49-e465-8772c3543a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create mapping from characters to integers and vice versa\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]  # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "0n39uJuUQbAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "V4H0AjeCQa9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLH_cdFfQtrE",
        "outputId": "207054de-c8bf-4491-d7b5-879cd3ad5753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hendrix lyrics"
      ],
      "metadata": {
        "id": "B3y7lfaPKTsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('spotify_millsongdata.csv',  engine='python', error_bad_lines=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAriGzK7KS4-",
        "outputId": "2e85b149-23bc-4619-fcc5-87bb9041ba91"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-102-265e00c0024e>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv('spotify_millsongdata.csv',  engine='python', error_bad_lines=False)\n",
            "Skipping line 28662: unexpected end of data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41FlpcCcKaYr",
        "outputId": "882024b1-ba56-4813-f725-f8aabe68a3f9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28660, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-8gw-JM2KaRz",
        "outputId": "a39ce0ca-78fe-4a35-8315-bbd574b1d4b1"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              artist                   song  \\\n",
              "0               ABBA  Ahe's My Kind Of Girl   \n",
              "1               ABBA       Andante, Andante   \n",
              "2               ABBA         As Good As New   \n",
              "3               ABBA                   Bang   \n",
              "4               ABBA       Bang-A-Boomerang   \n",
              "...              ...                    ...   \n",
              "28655  Dan Fogelberg      Our Last Farewell   \n",
              "28656  Dan Fogelberg       Part Of The Plan   \n",
              "28657  Dan Fogelberg          Promises Made   \n",
              "28658  Dan Fogelberg     Rhythm Of The Rain   \n",
              "28659  Dan Fogelberg      Run For The Roses   \n",
              "\n",
              "                                                    link  \\\n",
              "0             /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
              "1                  /a/abba/andante+andante_20002708.html   \n",
              "2                   /a/abba/as+good+as+new_20003033.html   \n",
              "3                             /a/abba/bang_20598415.html   \n",
              "4                 /a/abba/bang+a+boomerang_20002668.html   \n",
              "...                                                  ...   \n",
              "28655   /d/dan+fogelberg/our+last+farewell_20035714.html   \n",
              "28656    /d/dan+fogelberg/part+of+the+plan_20035777.html   \n",
              "28657       /d/dan+fogelberg/promises+made_20035748.html   \n",
              "28658  /d/dan+fogelberg/rhythm+of+the+rain_20035806.html   \n",
              "28659   /d/dan+fogelberg/run+for+the+roses_20035791.html   \n",
              "\n",
              "                                                    text  \n",
              "0      Look at her face, it's a wonderful face  \\r\\nA...  \n",
              "1      Take it easy with me, please  \\r\\nTouch me gen...  \n",
              "2      I'll never know why I had to go  \\r\\nWhy I had...  \n",
              "3      Making somebody happy is a question of give an...  \n",
              "4      Making somebody happy is a question of give an...  \n",
              "...                                                  ...  \n",
              "28655  Once I loved you and you loved me  \\r\\nWe beli...  \n",
              "28656  I have these moments  \\r\\nAll steady and stron...  \n",
              "28657  Promises made  \\r\\nPromises broken  \\r\\nMeasur...  \n",
              "28658  [Chorus:]  \\r\\nListen to the rhythm of the fal...  \n",
              "28659  Born in the valley  \\r\\nAnd raised in the tree...  \n",
              "\n",
              "[28660 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-fa790bd4-e1ed-4d86-b45c-1604a708ce2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>song</th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Ahe's My Kind Of Girl</td>\n",
              "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
              "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Andante, Andante</td>\n",
              "      <td>/a/abba/andante+andante_20002708.html</td>\n",
              "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>As Good As New</td>\n",
              "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
              "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang</td>\n",
              "      <td>/a/abba/bang_20598415.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang-A-Boomerang</td>\n",
              "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28655</th>\n",
              "      <td>Dan Fogelberg</td>\n",
              "      <td>Our Last Farewell</td>\n",
              "      <td>/d/dan+fogelberg/our+last+farewell_20035714.html</td>\n",
              "      <td>Once I loved you and you loved me  \\r\\nWe beli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28656</th>\n",
              "      <td>Dan Fogelberg</td>\n",
              "      <td>Part Of The Plan</td>\n",
              "      <td>/d/dan+fogelberg/part+of+the+plan_20035777.html</td>\n",
              "      <td>I have these moments  \\r\\nAll steady and stron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28657</th>\n",
              "      <td>Dan Fogelberg</td>\n",
              "      <td>Promises Made</td>\n",
              "      <td>/d/dan+fogelberg/promises+made_20035748.html</td>\n",
              "      <td>Promises made  \\r\\nPromises broken  \\r\\nMeasur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28658</th>\n",
              "      <td>Dan Fogelberg</td>\n",
              "      <td>Rhythm Of The Rain</td>\n",
              "      <td>/d/dan+fogelberg/rhythm+of+the+rain_20035806.html</td>\n",
              "      <td>[Chorus:]  \\r\\nListen to the rhythm of the fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28659</th>\n",
              "      <td>Dan Fogelberg</td>\n",
              "      <td>Run For The Roses</td>\n",
              "      <td>/d/dan+fogelberg/run+for+the+roses_20035791.html</td>\n",
              "      <td>Born in the valley  \\r\\nAnd raised in the tree...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28660 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa790bd4-e1ed-4d86-b45c-1604a708ce2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-05257f66-58d0-4d34-a1f9-0e342c2f72ac\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05257f66-58d0-4d34-a1f9-0e342c2f72ac')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-05257f66-58d0-4d34-a1f9-0e342c2f72ac button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa790bd4-e1ed-4d86-b45c-1604a708ce2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa790bd4-e1ed-4d86-b45c-1604a708ce2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.query(\"artist == 'Jimi Hendrix'\").text.str.cat(sep='\\n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itNJSzyQKZ2U",
        "outputId": "608b9847-5e58-431e-b365-fabb9d4f2f5d"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26290"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dylan Lyrics Data - Chars\n",
        "Load data from [here](https://www.kaggle.com/datasets/cloudy17/bob-dylan-songs)"
      ],
      "metadata": {
        "id": "7IgaCOKjqavC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('clear.csv')"
      ],
      "metadata": {
        "id": "XxGrsUy2qajS"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check first lyric\n",
        "text = df.lyrics[0]\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "61X6z73gqhXa",
        "outputId": "e829e708-e1c8-4cce-ea12-7df09c5660b2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Come you ladies and you gentlemen, a-listen to my song\\n\\nSing it to you right, but you might think it’s wrong\\n\\nJust a little glimpse of a story I’ll tell\\n\\n’Bout an East Coast city that you all know well\\n\\nIt’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nOld New York City is a friendly old town\\n\\nFrom Washington Heights to Harlem on down\\n\\nThere’s a-mighty many people all millin’ all around\\n\\nThey’ll kick you when you’re up and knock you when you’re down\\n\\nIt’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nIt’s a mighty long ways from the Golden Gate\\n\\nTo Rockefeller Plaza ’n’ the Empire State.\\n\\nMister Rockefeller sets up as high as a bird\\n\\nOld Mister Empire never says a word\\n\\nIt’s hard times from the country\\n\\nLivin’ down in New York town\\n\\n\\n\\nWell, it’s up in the mornin’ tryin’ to find a job of work\\n\\nStand in one place till your feet begin to hurt\\n\\nIf you got a lot o’ money you can make yourself merry\\n\\nIf you only got a nickel, it’s the Staten Island Ferry\\n\\nAnd it’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nMister Hudson come a-sailin’ down the stream\\n\\nAnd old Mister Minuet paid for his dream\\n\\nBought your city on a one-way track\\n\\n’F I had my way I’d sell it right back\\n\\nAnd it’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nI’ll take all the smog in Cal-i-for-ne-ay\\n\\n’N’ every bit of dust in the Oklahoma plains\\n\\n’N’ the dirt in the caves of the Rocky Mountain mines\\n\\nIt’s all much cleaner than the New York kind\\n\\nAnd it’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nSo all you newsy people, spread the news around\\n\\nYou c’n listen to m’ story, listen to m’ song\\n\\nYou c’n step on my name, you c’n try ’n’ get me beat\\n\\nWhen I leave New York, I’ll be standin’ on my feet\\n\\nAnd it’s hard times in the city\\n\\nLivin’ down in New York town'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate lyrics into one string\n",
        "text = (\n",
        "  ''.join(\n",
        "    df['lyrics']\n",
        "    .str.replace('\\n \\n \\n \\n ', '\\n\\n\\n')\n",
        "    .str.replace('\\n \\n \\n ', '\\n\\n\\n')\n",
        "    .str.replace('\\n \\n ', '\\n\\n')\n",
        "    .str.replace('\\n ', '\\n')\n",
        "    .str.replace('\\n\\n\\n', '\\n\\n')\n",
        "    .str.replace('\\n\\n', '\\n')\n",
        "  )\n",
        ")"
      ],
      "metadata": {
        "id": "avFZleWCsE1K"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4erAIyNJ5i1",
        "outputId": "c6ea4aa7-0bce-42e8-f5db-cd80cf86c79b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "523786"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get char counts\n",
        "char_count = {}\n",
        "\n",
        "for char in text:\n",
        "    if char in char_count:\n",
        "        char_count[char] += 1\n",
        "    else:\n",
        "        char_count[char] = 1"
      ],
      "metadata": {
        "id": "4PI2F2Szw5B5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_char_count =  dict(sorted(char_count.items(), key=lambda item: item[1], reverse=True))"
      ],
      "metadata": {
        "id": "J6A5oIp1xA2c"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "Ysx6nbP2qlhN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEKjrb5Aqaei",
        "outputId": "4b70d964-7569-4733-8fe9-a68aac86d5f3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create mapping from characters to integers and vice versa\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s]  # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "0mdL3cWcx0YI"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test splits\n",
        "#data = torch.tensor(encode(text), dtype=torch.long)\n",
        "data = np.array(encode(text), dtype=np.int16)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "7kycSr_Px0Vq"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2LN6epIx0TM",
        "outputId": "715248eb-1ce2-4964-dca5-e0ae730251ab"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([26, 65, 63, 55,  2, 75, 65, 71,  2, 62, 51, 54, 59, 55, 69,  2, 51,\n",
              "       64, 54,  2], dtype=int16)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode(train_data[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GgWwtpz14JPe",
        "outputId": "4baf408d-b534-4da7-ddf6-82eaade67e4b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Come you ladies and you gentlemen, a-listen to my song\\nSing it to you right, but you might think it’'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(''.join(stoi.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52rFwMgf4ZRw",
        "outputId": "19887a46-73fd-4af8-8d81-bb27acdeab5d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u000b !\"'(),-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ`abcdefghijklmnopqrstuvwxyz¥©éñóü–—‘’“”… \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dylan Lyrics Data - Words"
      ],
      "metadata": {
        "id": "cllahlv10aq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('clear.csv')\n",
        "\n",
        "text = (\n",
        "  ''.join(\n",
        "    df['lyrics']\n",
        "    .str.replace('\\n \\n \\n \\n ', '\\n\\n\\n')\n",
        "    .str.replace('\\n \\n \\n ', '\\n\\n\\n')\n",
        "    .str.replace('\\n \\n ', '\\n\\n')\n",
        "    .str.replace('\\n ', '\\n')\n",
        "    .str.replace('\\n\\n\\n', '\\n\\n')\n",
        "    .str.replace('\\n\\n', '\\n')\n",
        "  )\n",
        ")"
      ],
      "metadata": {
        "id": "Jr5Hfgvr0cKa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "metadata": {
        "id": "2zTF_uRM0kpy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_tokenized = tokenizer(text)"
      ],
      "metadata": {
        "id": "QVSNRjQp04sH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = sorted(list(set(text_tokenized)))\n",
        "vocab_size = len(tokens)\n",
        "\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LqlLY6Z76fk",
        "outputId": "40b6a368-0835-4bd7-d44a-b107a899eead"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8774"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create mapping from characters to integers and vice versa\n",
        "stoi = { ch:i for i,ch in enumerate(tokens) }\n",
        "itos = { i:ch for i,ch in enumerate(tokens) }\n",
        "encode = lambda s: [stoi[c] for c in s]  # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "CdJL2-Ik04c9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test splits\n",
        "data = torch.tensor(encode(text_tokenized), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "KWbTrOzQ0adk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImJaUg9e8RvO",
        "outputId": "353c2d66-e5cf-4ee5-e53b-23ce1cffa844"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1469, 8498, 4121,  298, 8498, 3089,    4,   70, 7620, 4910])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dylan Lyrics - Words (Karpathy)"
      ],
      "metadata": {
        "id": "UesWYZfDb7rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('clear.csv')"
      ],
      "metadata": {
        "id": "TYeiB2H1b8fW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check first lyric\n",
        "text = df.lyrics[0]\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "hH_K5NaXcOnp",
        "outputId": "c1cbf713-33a8-4b2d-9503-cbcbf9b46726"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Come you ladies and you gentlemen, a-listen to my song\\n\\nSing it to you right, but you might think it’s wrong\\n\\nJust a little glimpse of a story I’ll tell\\n\\n’Bout an East Coast city that you all know well\\n\\nIt’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nOld New York City is a friendly old town\\n\\nFrom Washington Heights to Harlem on down\\n\\nThere’s a-mighty many people all millin’ all around\\n\\nThey’ll kick you when you’re up and knock you when you’re down\\n\\nIt’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nIt’s a mighty long ways from the Golden Gate\\n\\nTo Rockefeller Plaza ’n’ the Empire State.\\n\\nMister Rockefeller sets up as high as a bird\\n\\nOld Mister Empire never says a word\\n\\nIt’s hard times from the country\\n\\nLivin’ down in New York town\\n\\n\\n\\nWell, it’s up in the mornin’ tryin’ to find a job of work\\n\\nStand in one place till your feet begin to hurt\\n\\nIf you got a lot o’ money you can make yourself merry\\n\\nIf you only got a nickel, it’s the Staten Island Ferry\\n\\nAnd it’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nMister Hudson come a-sailin’ down the stream\\n\\nAnd old Mister Minuet paid for his dream\\n\\nBought your city on a one-way track\\n\\n’F I had my way I’d sell it right back\\n\\nAnd it’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nI’ll take all the smog in Cal-i-for-ne-ay\\n\\n’N’ every bit of dust in the Oklahoma plains\\n\\n’N’ the dirt in the caves of the Rocky Mountain mines\\n\\nIt’s all much cleaner than the New York kind\\n\\nAnd it’s hard times in the city\\n\\nLivin’ down in New York town\\n\\n\\n\\nSo all you newsy people, spread the news around\\n\\nYou c’n listen to m’ story, listen to m’ song\\n\\nYou c’n step on my name, you c’n try ’n’ get me beat\\n\\nWhen I leave New York, I’ll be standin’ on my feet\\n\\nAnd it’s hard times in the city\\n\\nLivin’ down in New York town'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate lyrics into one string\n",
        "text = (\n",
        "  ''.join(\n",
        "    df['lyrics']\n",
        "    .str.replace('\\n \\n \\n \\n ', '\\n\\n\\n')\n",
        "    .str.replace('\\n \\n \\n ', '\\n\\n\\n')\n",
        "    .str.replace('\\n \\n ', '\\n\\n')\n",
        "    .str.replace('\\n ', '\\n')\n",
        "    .str.replace('\\n\\n\\n', '\\n\\n')\n",
        "    .str.replace('\\n\\n', '\\n')\n",
        "  )\n",
        ")"
      ],
      "metadata": {
        "id": "PYxCG5ircOle"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "n = len(text)\n",
        "train_data = text[:int(n*0.9)]\n",
        "val_data = text[int(n*0.9):]\n",
        "\n",
        "n, len(train_data), len(val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YL16_ObbcOek",
        "outputId": "bbf2ca16-4c3e-4d70-b7a0-7ce7db506b1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(523786, 471407, 52379)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode with tiktoken gpt2 bpe\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "# Encode\n",
        "train_ids = enc.encode_ordinary(train_data)\n",
        "val_ids = enc.encode_ordinary(val_data)\n",
        "\n",
        "# Dtype\n",
        "train_data = np.array(train_ids, dtype=np.uint16)\n",
        "val_data = np.array(val_ids, dtype=np.uint16)\n",
        "\n",
        "print(f\"train has {len(train_data):,} tokens\")\n",
        "print(f\"val has {len(val_data):,} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3wplekLcq3N",
        "outputId": "d5e24123-cdf9-47d3-9763-c3214d9f23b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train has 136,916 tokens\n",
            "val has 14,718 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = sorted(list(set(train_ids + val_ids)))\n",
        "vocab_size = len(tokens)\n",
        "\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6jq-F8Yr0cC",
        "outputId": "689c4e4f-f487-449b-de53-5b3a5af586e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8861"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9YlypBpwRsI",
        "outputId": "11988af5-6f6f-48c6-ab72-bc33f5b08c33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16773,   345, 17308,   290,   345, 28527,    11,   257,    12,\n",
              "        4868], dtype=uint16)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max token number\n",
        "max(max(train_data),max(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvjdd-9EzgSi",
        "outputId": "9a37325d-af2b-48da-920b-800983cd7b97"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50255"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "mqP7iydhQ289"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Hyperparamters - gpu\n",
        "# batch_size = 64      # number of independent sequences to process in parallel\n",
        "# block_size = 256     # context length\n",
        "# max_iters = 5_000    # training iterations\n",
        "# eval_interval = 500  # how often to evaluate the loss on train and val sets\n",
        "# eval_iters = 200     # how many iterations to average loss over when evaluating\n",
        "# learning_rate = 3e-4 # learning rate param\n",
        "# n_embed = 384         # embedding size\n",
        "# n_layer = 6          # number of transformer blocks\n",
        "# dropout = 0.2        # dropout rate\n",
        "# n_head = 6           # number of heads\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "p4bE39y42yT1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Hyperparamters - cpu\n",
        "# batch_size = 32      # number of independent sequences to process in parallel\n",
        "# block_size = 16       # context length\n",
        "# max_iters = 5_000    # training iterations\n",
        "# eval_interval = 100  # how often to evaluate the loss on train and val sets\n",
        "# eval_iters = 200     # how many iterations to average loss over when evaluating\n",
        "# learning_rate = 1e-3 # learning rate param\n",
        "# n_embed = 128         # embedding size\n",
        "# n_layer = 4          # number of transformer blocks\n",
        "# dropout = 0.0        # dropout rate\n",
        "# n_head = 4           # number of heads\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "SRbscvWO3ecZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RS"
      ],
      "metadata": {
        "id": "Xw3-vxckBGLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparamters - gpu v1 - char format\n",
        "\n",
        "out_dir = '/content/out-char'\n",
        "eval_interval = 250  # how often to evaluate the loss on train and val sets\n",
        "eval_iters = 200     # how many iterations to average loss over when evaluating\n",
        "log_interval = 10    # dont print too often\n",
        "\n",
        "# we expct to overfit: save when val improves\n",
        "always_save_checkpoint = False\n",
        "\n",
        "# logger\n",
        "wandb_log = False\n",
        "wandb_project = 'dylan-char'\n",
        "wandb_run_name = 'mini-gpt'\n",
        "\n",
        "gradient_accumulation_steps = 1\n",
        "batch_size = 64      # number of independent sequences to process in parallel\n",
        "block_size = 256     # context length\n",
        "\n",
        "\n",
        "# baby gpt-model\n",
        "learning_rate = 1e-4\n",
        "max_iters = 5_000    # training iterations\n",
        "lr_decay_iters = 5000\n",
        "min_lr = 1e-4        # lr / 10\n",
        "beta2 = 0.99         # make bigger because number of tokens per iters is small\n",
        "warm_up_iters = 100\n",
        "\n",
        "n_embed = 384        # embedding size\n",
        "n_layer = 6          # number of transformer blocks\n",
        "n_head = 6           # number of heads of each transformer block\n",
        "dropout = 0.2        # dropout rate\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "Hlm6WzLHcfju"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch data"
      ],
      "metadata": {
        "id": "gJxco2CTOZ4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "    \"\"\"Generate a small random batch of data of inputs 'x'\n",
        "    and targets 'y'\n",
        "    \"\"\"\n",
        "    # get random index\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(\n",
        "        low=0,\n",
        "        high=len(data) - block_size,\n",
        "        size=(batch_size,))\n",
        "\n",
        "    # get the context for each index, and stack it into\n",
        "    # rows.\n",
        "    x = torch.stack([torch.from_numpy((data[i : i+block_size]).astype(np.int64)) for i in ix])\n",
        "    y = torch.stack([torch.from_numpy((data[i+1 : i+1+block_size]).astype(np.int64)) for i in ix])\n",
        "\n",
        "\n",
        "    #if device == 'cuda':\n",
        "      # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
        "      # x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
        "\n",
        "    #else:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "_TGc4VrxOb1W"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = get_batch(split='train')"
      ],
      "metadata": {
        "id": "91lIgURhRWVz"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0DExn6xvYwI",
        "outputId": "939b9c54-6e99-462b-80ba-81ea9f30081a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHKBezeZRZ5u",
        "outputId": "f3be0fa3-bec4-4bdb-b514-8d86aef4fa6a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0, 32, 64,  2, 58, 55, 51, 72, 55, 64,  2, 65, 68,  2, 59, 64,  2, 58,\n",
              "         55, 62, 62, 23,  0,  0, 24, 68, 55,  2, 75, 65, 71,  2, 68, 55, 51, 54,\n",
              "         75,  8,  2, 51, 68, 55,  2, 75, 65, 71,  2, 68, 55, 51, 54, 75, 23,  0,\n",
              "          0, 31, 51, 72, 55,  2, 75, 65, 71,  2, 57, 65, 70,  2, 69, 65, 63, 55,\n",
              "          2, 71, 64, 56, 59, 64, 59, 69, 58, 55, 54,  2, 52, 71, 69, 59, 64, 55,\n",
              "         69, 69, 23,  0, 32, 69,  2, 70, 58, 55, 68, 55,  2, 69, 65, 63, 55, 70,\n",
              "         58, 59, 64, 57,  2, 58, 65, 62, 54, 59, 64, 57,  2, 75, 65, 71,  2, 52,\n",
              "         51, 53, 61, 23,  0, 24, 68, 55,  2, 75, 65, 71,  2, 70, 58, 59, 64, 61,\n",
              "         59, 64, 57,  2, 56, 65, 68,  2, 75, 65, 71, 68, 69, 55, 62, 56,  0, 38,\n",
              "         68,  2, 51, 68, 55,  2, 75, 65, 71,  2, 56, 65, 62, 62, 65, 73, 59, 64,\n",
              "         57,  2, 70, 58, 55,  2, 66, 51, 53, 61, 23,  0,  0, 24, 68, 55,  2, 75,\n",
              "         65, 71,  2, 68, 55, 51, 54, 75,  8,  2, 58, 65, 66, 55,  2, 75, 65, 71,\n",
              "         86, 68, 55,  2, 68, 55, 51, 54, 75,  0, 24, 68, 55,  2, 75, 65, 71,  2,\n",
              "         68, 55, 51, 54, 75, 23,  0,  0, 24, 68, 55,  2, 75, 65, 71,  2, 68, 55,\n",
              "         51, 54, 75,  2], device='cuda:0'),\n",
              " tensor([32, 64,  2, 58, 55, 51, 72, 55, 64,  2, 65, 68,  2, 59, 64,  2, 58, 55,\n",
              "         62, 62, 23,  0,  0, 24, 68, 55,  2, 75, 65, 71,  2, 68, 55, 51, 54, 75,\n",
              "          8,  2, 51, 68, 55,  2, 75, 65, 71,  2, 68, 55, 51, 54, 75, 23,  0,  0,\n",
              "         31, 51, 72, 55,  2, 75, 65, 71,  2, 57, 65, 70,  2, 69, 65, 63, 55,  2,\n",
              "         71, 64, 56, 59, 64, 59, 69, 58, 55, 54,  2, 52, 71, 69, 59, 64, 55, 69,\n",
              "         69, 23,  0, 32, 69,  2, 70, 58, 55, 68, 55,  2, 69, 65, 63, 55, 70, 58,\n",
              "         59, 64, 57,  2, 58, 65, 62, 54, 59, 64, 57,  2, 75, 65, 71,  2, 52, 51,\n",
              "         53, 61, 23,  0, 24, 68, 55,  2, 75, 65, 71,  2, 70, 58, 59, 64, 61, 59,\n",
              "         64, 57,  2, 56, 65, 68,  2, 75, 65, 71, 68, 69, 55, 62, 56,  0, 38, 68,\n",
              "          2, 51, 68, 55,  2, 75, 65, 71,  2, 56, 65, 62, 62, 65, 73, 59, 64, 57,\n",
              "          2, 70, 58, 55,  2, 66, 51, 53, 61, 23,  0,  0, 24, 68, 55,  2, 75, 65,\n",
              "         71,  2, 68, 55, 51, 54, 75,  8,  2, 58, 65, 66, 55,  2, 75, 65, 71, 86,\n",
              "         68, 55,  2, 68, 55, 51, 54, 75,  0, 24, 68, 55,  2, 75, 65, 71,  2, 68,\n",
              "         55, 51, 54, 75, 23,  0,  0, 24, 68, 55,  2, 75, 65, 71,  2, 68, 55, 51,\n",
              "         54, 75,  2, 56], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimate loss"
      ],
      "metadata": {
        "id": "lL3-7YTETIBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    \"\"\"Averages out the loss over multiple batches, in order\n",
        "    to get a better estimate of the loss.\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "\n",
        "    # set model to evaluation phase\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "\n",
        "    # set model to training phase\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "Peq7wepqRzeo"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer `Head`"
      ],
      "metadata": {
        "id": "0-8KqDj7TXH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define `Self Attention` model. The idea behind `self-attention` is to gather information from the past, in a data-dependant way."
      ],
      "metadata": {
        "id": "SzeFNLqUWnOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example,\n",
        "\n",
        "$X_{4x8x32} * X_{32x16} = X_{4x8x16}$\n",
        "\n",
        "where,\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "context_length = 8\n",
        "\n",
        "embedding_dimension = 32\n",
        "\n",
        "head_size = 16"
      ],
      "metadata": {
        "id": "HKnTqxL0crdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  \"\"\"One head of self-attention.\n",
        "  The idea is that each token has a:\n",
        "    - key\n",
        "    - query\n",
        "    - value\n",
        "  Then, for each token, the key queries every other token, and \"resonates\"\n",
        "  with those where the link is stronger. These relationships are stored in\n",
        "  a \"weights\" vector, which is applied over the value of each token, to weight\n",
        "  each token in the past context.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, head_size):\n",
        "    super().__init__()\n",
        "\n",
        "    # Create independent and parallel key and query for each token\n",
        "    self.key = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.query = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.value = nn.Linear(n_embed, head_size, bias=False)\n",
        "    self.register_buffer(\n",
        "        'tril',\n",
        "        torch.tril(torch.ones(block_size, block_size))\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    B, T, C = x.shape\n",
        "    k = self.key(x)   # (B, T, C) @ (C, head_size) -> (B, T, head_size)\n",
        "    q = self.query(x) # (B, T, C) @ (C, head_size) -> (B, T, head_size)\n",
        "\n",
        "    # Compute attention scores, i.e. affinities\n",
        "    wei = q @ k.transpose(-1, -2) * C**-0.5 # (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "    wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "    wei = self.dropout(wei)\n",
        "\n",
        "    # Perform the weighted aggregation of the values\n",
        "    v = self.value(x)\n",
        "    out = wei @ v\n",
        "    return out"
      ],
      "metadata": {
        "id": "ic20NvmvTKYR"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MulitHeadAttention(nn.Module):\n",
        "  \"\"\"Multiple heads of self-attention in parallel.\n",
        "  Note: head_size * n_heads = n_embed\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_heads, head_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.heads = nn.ModuleList(\n",
        "        [Head(head_size) for _ in range(num_heads)]\n",
        "    )\n",
        "\n",
        "    self.proj = nn.Linear(n_embed, n_embed)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Concatenate the heads over the channel dimension, i.e. horizontally,\n",
        "    # one besides the other, column-wise\n",
        "    out = torch.cat(\n",
        "        [h(x) for h in self.heads],\n",
        "        dim=-1\n",
        "    ) # (B, T, head_size * num_heads)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out"
      ],
      "metadata": {
        "id": "51OtHTR3WwZB"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  \"\"\"A simple linear layer followed by a non-linearity\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, n_embed):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(n_embed, 4 * n_embed),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4 * n_embed, n_embed),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "bQVCnq46W4OY"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  \"\"\"Transformer block: communication followed by computation\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, n_embed, n_head):\n",
        "    super().__init__()\n",
        "    head_size = n_embed // n_head\n",
        "    self.sa = MulitHeadAttention(n_head, head_size)\n",
        "    self.ffwd = FeedForward(n_embed)\n",
        "    self.ln1 = nn.LayerNorm(n_embed)\n",
        "    self.ln2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "HpBYcxikXEQn"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DylanGPT Model"
      ],
      "metadata": {
        "id": "jts1n5x4t8Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DylanGPT(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "\n",
        "    # Embeddings\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n",
        "    self.postition_embedding_table = nn.Embedding(block_size, n_embed)\n",
        "\n",
        "    # Transformer Blocks\n",
        "    self.blocks = nn.Sequential(*[\n",
        "        TransformerBlock(n_embed, n_head=n_head) for _ in range(n_layer)])\n",
        "\n",
        "    # Final layer norm\n",
        "    self.ln_f = nn.LayerNorm(n_embed)\n",
        "\n",
        "    # LLM head\n",
        "    self.lm_head = nn.Linear(n_embed, vocab_size)\n",
        "\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "\n",
        "    B, T = idx.shape\n",
        "    token_embed = self.token_embedding_table(idx)\n",
        "    pos_embed = self.postition_embedding_table(torch.arange(T, device=device))\n",
        "\n",
        "    x = token_embed + pos_embed\n",
        "    x = self.blocks(x)\n",
        "    x = self.ln_f(x)\n",
        "    logits = self.lm_head(x)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      # F.cross_entropy requires a (B, C, T) shape\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_cond = idx[:, -block_size:]\n",
        "\n",
        "      logits, loss = self(idx_cond)\n",
        "\n",
        "      logits = logits[:, -1, :]\n",
        "      probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "      idx_next = torch.multinomial(probs, num_samples=1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "MDWjzx4-0ImD"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "2DcosgCH2tx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# vocab size\n",
        "#vocab_size = 50257\n",
        "\n",
        "# model\n",
        "model = DylanGPT(vocab_size=vocab_size)\n",
        "m = model.to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# loop\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlUrIsaw0Ijx",
        "outputId": "ff1182c5-afb2-4fd5-e147-8570aa92d72e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.6613, val loss 4.6762\n",
            "step 250: train loss 2.4087, val loss 2.4487\n",
            "step 500: train loss 2.3588, val loss 2.4106\n",
            "step 750: train loss 2.2637, val loss 2.3228\n",
            "step 1000: train loss 2.0438, val loss 2.1289\n",
            "step 1250: train loss 1.9045, val loss 2.0089\n",
            "step 1500: train loss 1.7985, val loss 1.9187\n",
            "step 1750: train loss 1.7158, val loss 1.8511\n",
            "step 2000: train loss 1.6443, val loss 1.7969\n",
            "step 2250: train loss 1.5958, val loss 1.7597\n",
            "step 2500: train loss 1.5415, val loss 1.7264\n",
            "step 2750: train loss 1.4981, val loss 1.6976\n",
            "step 3000: train loss 1.4607, val loss 1.6858\n",
            "step 3250: train loss 1.4202, val loss 1.6566\n",
            "step 3500: train loss 1.3869, val loss 1.6411\n",
            "step 3750: train loss 1.3545, val loss 1.6243\n",
            "step 4000: train loss 1.3264, val loss 1.6216\n",
            "step 4250: train loss 1.2963, val loss 1.6124\n",
            "step 4500: train loss 1.2727, val loss 1.6092\n",
            "step 4750: train loss 1.2410, val loss 1.5933\n",
            "CPU times: user 18min 7s, sys: 14.8 s, total: 18min 22s\n",
            "Wall time: 18min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Hyperparamters - gpu v1 - char format\n",
        "\n",
        "# out_dir = '/content/out-char'\n",
        "# eval_interval = 250  # how often to evaluate the loss on train and val sets\n",
        "# eval_iters = 200     # how many iterations to average loss over when evaluating\n",
        "# log_interval = 10    # dont print too often\n",
        "\n",
        "# # we expct to overfit: save when val improves\n",
        "# always_save_checkpoint = False\n",
        "\n",
        "# # logger\n",
        "# wandb_log = False\n",
        "# wandb_project = 'dylan-char'\n",
        "# wandb_run_name = 'mini-gpt'\n",
        "\n",
        "# gradient_accumulation_steps = 1\n",
        "# batch_size = 64      # number of independent sequences to process in parallel\n",
        "# block_size = 256     # context length\n",
        "\n",
        "\n",
        "# # baby gpt-model\n",
        "# learning_rate = 1e-4\n",
        "# max_iters = 5_000    # training iterations\n",
        "# lr_decay_iters = 5000\n",
        "# min_lr = 1e-4        # lr / 10\n",
        "# beta2 = 0.99         # make bigger because number of tokens per iters is small\n",
        "# warm_up_iters = 100\n",
        "\n",
        "# n_embed = 384        # embedding size\n",
        "# n_layer = 6          # number of transformer blocks\n",
        "# n_head = 6           # number of heads of each transformer block\n",
        "# dropout = 0.2        # dropout rate\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# step 0: train loss 4.6613, val loss 4.6762\n",
        "# step 250: train loss 2.4087, val loss 2.4487\n",
        "# step 500: train loss 2.3588, val loss 2.4106\n",
        "# step 750: train loss 2.2637, val loss 2.3228\n",
        "# step 1000: train loss 2.0438, val loss 2.1289\n",
        "# step 1250: train loss 1.9045, val loss 2.0089\n",
        "# step 1500: train loss 1.7985, val loss 1.9187\n",
        "# step 1750: train loss 1.7158, val loss 1.8511\n",
        "# step 2000: train loss 1.6443, val loss 1.7969\n",
        "# step 2250: train loss 1.5958, val loss 1.7597\n",
        "# step 2500: train loss 1.5415, val loss 1.7264\n",
        "# step 2750: train loss 1.4981, val loss 1.6976\n",
        "# step 3000: train loss 1.4607, val loss 1.6858\n",
        "# step 3250: train loss 1.4202, val loss 1.6566\n",
        "# step 3500: train loss 1.3869, val loss 1.6411\n",
        "# step 3750: train loss 1.3545, val loss 1.6243\n",
        "# step 4000: train loss 1.3264, val loss 1.6216\n",
        "# step 4250: train loss 1.2963, val loss 1.6124\n",
        "# step 4500: train loss 1.2727, val loss 1.6092\n",
        "# step 4750: train loss 1.2410, val loss 1.5933\n",
        "# CPU times: user 18min 7s, sys: 14.8 s, total: 18min 22s\n",
        "# Wall time: 18min 17s"
      ],
      "metadata": {
        "id": "b8pirTmtM1lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To do:\n",
        "- add plots for loss (train/val) and others\n",
        "- find a good lr\n",
        "- optimize initialization\n",
        "- optimize learning rate"
      ],
      "metadata": {
        "id": "byhcw7RIUtLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate from model\n",
        "context = torch.zeros((1,1),dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_-zsRms0IhI",
        "outputId": "10ebcb2c-a9e7-4506-95d5-92e2fffed6f2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "When the devy them donce Hix\n",
            "Just Can the triwn\n",
            "But it’s a smile\n",
            "We music out he down\n",
            "Or go, ooh, let Ma, Mourca\n",
            "La feet yel\n",
            "I was the only lamen your manight poss and has about with they’re rulefuled\n",
            "Love you wea! Evstis bad better hand to be new\n",
            "Suble couldn’t leave you hear anyter\n",
            "I know what it’s nuauth a eapose,one-deep\n",
            "\n",
            "I creight pretty bus’ry on the churres\n",
            "I can want Henry\n",
            "Well, thenry I go back right to a trying flow\n",
            "What to the car of the even certs at the bark\n",
            "I coffee the boat of whe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add temperature"
      ],
      "metadata": {
        "id": "qslkvGByUW9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T = 0.7 # (0,1])\n",
        "\n",
        "idx = torch.zeros((1,1),dtype=torch.long, device=device)\n",
        "for _ in range(500):\n",
        "    idx_cond = idx[:, -block_size:]\n",
        "\n",
        "    logits, loss = m(idx_cond)\n",
        "\n",
        "    logits = logits[:, -1, :] * 1/T\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "    idx_next = torch.multinomial(probs, num_samples=1)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "print(decode(idx[0].detach().cpu().numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BMoe38t6GP3",
        "outputId": "c585d0e5-8e57-4060-e534-e915e2f44b22"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ill be a broken in the made of the streets\n",
            "The pastander, standing has kinda in a proul of heart\n",
            "And death of the steel of time\n",
            "I was sing in a thine that wind\n",
            "I would keep highold for from the wings like it to the wall\n",
            "I was the gray fool, making miles home\n",
            "Eatines I right for the eason to the slame\n",
            "I was someone every with a tray that I knews the trun\n",
            "I don’t eservery the storm fall\n",
            "You know at sometimes of the strames away\n",
            "\n",
            "Of a pattee sun if your home\n",
            "\n",
            "Put your people that the fust it know\n",
            "T\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T = 0.6 # (0,1])\n",
        "\n",
        "idx = torch.zeros((1,1),dtype=torch.long, device=device)\n",
        "for _ in range(500):\n",
        "    idx_cond = idx[:, -block_size:]\n",
        "\n",
        "    logits, loss = m(idx_cond)\n",
        "\n",
        "    logits = logits[:, -1, :] * 1/T\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "    idx_next = torch.multinomial(probs, num_samples=1)\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "print(decode(idx[0].detach().cpu().numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r10aPiNW6yH6",
        "outputId": "c62b620e-d6b7-4b1e-defd-ba96c5d7241f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I’m a part of morals\n",
            "An’ the world of my heart\n",
            "In something the expeclains, he pulled of the was in here\n",
            "But she ain’t right no to the Leven, the morning\n",
            "I stand of the passion, the man sease the begins\n",
            "She bearing the end song of a parkets\n",
            "\n",
            "Well, the sing for at there’s was a sheem of a harm\n",
            "\n",
            "I said, “Shadon you mad take it of the way know the was the parts\n",
            "We lawer, the made of the man, my is hard a waiting white the back to see the story\n",
            "Say me a door and I can see the stare of the fields of \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kqpI5SgXc8lZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}